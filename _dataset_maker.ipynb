{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (options: 100k, 1m, 10m, 20m, 25m)\n",
    "DATASET_SIZE: str = '1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:44:10.823098: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-04 12:44:10.873805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-04 12:44:10.873850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-04 12:44:10.874986: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-04 12:44:10.883079: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-04 12:44:10.884416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 12:44:12.254442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-04 12:44:15.164657: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-04 12:44:15.165261: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "ratings_dataset, ratings_dataset_info = tfds.load(\n",
    "    name = f'movielens/{DATASET_SIZE}-ratings',\n",
    "    # MovieLens dataset is not splitted into `train` and `test` sets by default.\n",
    "    # So TFDS has put it all into `train` split. We load it completely and split\n",
    "    # it manually.\n",
    "    split = 'train',\n",
    "    # `with_info=True` makes the `load` function return a `tfds.core.DatasetInfo`\n",
    "    # object containing dataset metadata like version, description, homepage,\n",
    "    # citation, etc.\n",
    "    with_info = True\n",
    ")\n",
    "\n",
    "# Convert the tf.data.DataFrame into a DataFrame.\n",
    "df = tfds.as_dataframe(ratings_dataset, ratings_dataset_info)\n",
    "\n",
    "# Convert byte values to strings.\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the ratings with only the relevant columns.\n",
    "# Columns: user_id, movie_id, timestamp, user_rating\n",
    "\n",
    "ratings_df_columns = [\n",
    "    'user_id',\n",
    "    'movie_id',\n",
    "    'timestamp',\n",
    "    'user_rating',\n",
    "]\n",
    "ratings_df = df.loc[:, ratings_df_columns]\n",
    "\n",
    "# Remove duplicates\n",
    "ratings_df.drop_duplicates(inplace=True)\n",
    "\n",
    "ratings_df.to_parquet(f'data/{DATASET_SIZE}-ratings.parquet', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the movie titles in the dataset contain their release years.\n",
    "# Extracting this detail and treating it as a separate feature is more \n",
    "# valuable than leaving it combined with the title.\n",
    "\n",
    "movies_df_columns = [\n",
    "    'movie_id',\n",
    "    'movie_title',\n",
    "    'movie_genres',\n",
    "]\n",
    "movies_df = df.loc[:, movies_df_columns]\n",
    "\n",
    "# Extract the release years into a separate column.\n",
    "movies_df['movie_release_year'] = movies_df['movie_title'].str.extract(r'\\((\\d{4})\\)')\n",
    "\n",
    "# Remove the release years from the movie titles.\n",
    "movies_df['movie_title'] = movies_df['movie_title'].str.replace(r'\\s*\\(\\d{4}\\)\\s*', '', regex=True)\n",
    "\n",
    "movies_df['movie_genres'] = movies_df['movie_genres'].apply(tuple)  # Convert the genres into a tuple.\n",
    "\n",
    "# Remove duplicates\n",
    "movies_df.drop_duplicates(inplace=True)\n",
    "\n",
    "movies_df.to_parquet(f'data/{DATASET_SIZE}-movies.parquet', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the user features into a separate DataFrame.\n",
    "# Columns: user_id, user_gender, user_raw_age, user_zip_code,\n",
    "# user_bucketized_age, user_occupation_text, user_occupation_label\n",
    "\n",
    "users_df_columns = [\n",
    "    'user_id',\n",
    "    'user_gender',\n",
    "    # 'raw_user_age',\n",
    "    'user_zip_code',\n",
    "    'bucketized_user_age',\n",
    "    # 'user_occupation_text',\n",
    "    'user_occupation_label',\n",
    "]\n",
    "users_df = df.loc[:, users_df_columns]\n",
    "\n",
    "users_df.rename(\n",
    "    columns = {\n",
    "        'bucketized_user_age': 'user_bucketized_age'\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "users_df['user_gender'] = users_df['user_gender'].apply(lambda x: int(x))  # Cast booleans to integers\n",
    "\n",
    "# Remove duplicates\n",
    "users_df.drop_duplicates(inplace=True)\n",
    "\n",
    "users_df.to_parquet(f'data/{DATASET_SIZE}-users.parquet', compression='brotli')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
